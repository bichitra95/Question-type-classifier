{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question type classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem is tackeled using the concept of bag of words commonly used in NLP as there is very less words in each question. After bag of words, we used Term frequency and Inverse Document frequency to to give weightage to each words found in a sentence and the training set. After that we have used different machine learning techniques and identified that Randomforest classifier as the suitable algorithm to use. And obtain more that 92% of F1 score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('LabelledData (1).txt',sep=',,,',names=['question','label'],engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how did serfdom develop in and then leave russ...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what films featured the character popeye doyle ?</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i find a list of celebrities ' real na...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what fowl grabs the spotlight after the chines...</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the full form of .com ?</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question     label\n",
       "0  how did serfdom develop in and then leave russ...   unknown\n",
       "1  what films featured the character popeye doyle ?       what\n",
       "2  how can i find a list of celebrities ' real na...   unknown\n",
       "3  what fowl grabs the spotlight after the chines...      what\n",
       "4                   what is the full form of .com ?       what"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Removing unwanted spaces from both the ends\n",
    "\n",
    "train['label']=train['label'].apply(lambda x: x.strip())\n",
    "train['question']=train['question'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1483</td>\n",
       "      <td>1483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1476</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>what is the speed of the mississippi river ?</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question label\n",
       "count                                           1483  1483\n",
       "unique                                          1476     5\n",
       "top     what is the speed of the mississippi river ?  what\n",
       "freq                                               3   609"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()# shows duplicate questions as count and unique are different for question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "what           606\n",
       "who            401\n",
       "unknown        271\n",
       "affirmation    102\n",
       "when            96\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">question</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>affirmation</th>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>is this considered a \"fill hose\" ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unknown</th>\n",
       "      <td>271</td>\n",
       "      <td>271</td>\n",
       "      <td>which japanese car maker had its biggest perce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>what</th>\n",
       "      <td>606</td>\n",
       "      <td>606</td>\n",
       "      <td>what was the name of the sitcom that alyssa mi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>when</th>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>when were camcorders introduced in malaysia ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>who</th>\n",
       "      <td>401</td>\n",
       "      <td>401</td>\n",
       "      <td>who played the ringo kid in the 1939 film stag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            question         \\\n",
       "               count unique   \n",
       "label                         \n",
       "affirmation      102    102   \n",
       "unknown          271    271   \n",
       "what             606    606   \n",
       "when              96     96   \n",
       "who              401    401   \n",
       "\n",
       "                                                                     \n",
       "                                                           top freq  \n",
       "label                                                                \n",
       "affirmation                 is this considered a \"fill hose\" ?    1  \n",
       "unknown      which japanese car maker had its biggest perce...    1  \n",
       "what         what was the name of the sitcom that alyssa mi...    1  \n",
       "when             when were camcorders introduced in malaysia ?    1  \n",
       "who          who played the ringo kid in the 1939 film stag...    1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(by='label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1476</td>\n",
       "      <td>1476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1476</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>where is the danube ?</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     question label\n",
       "count                    1476  1476\n",
       "unique                   1476     5\n",
       "top     where is the danube ?  what\n",
       "freq                        1   606"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filtering the punctuations from the sentence and tokenizing the sentence into words\n",
    "def text_process(question):\n",
    "    noponc=[word for word in question if word not in string.punctuation]\n",
    "    noponc=''.join(noponc).strip()\n",
    "    #return [word for word in noponc.split() if word.lower() in stopwords.words('english')]\n",
    "    return noponc.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring for vectorizing questions in to bow using predefined analyzer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow_trasformer=CountVectorizer(analyzer=text_process).fit(train['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3685\n"
     ]
    }
   ],
   "source": [
    "print(len(bow_trasformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messages_bow=bow_trasformer.transform(train['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1476, 3685)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring for transforming the bag of words table into Tfidf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_transformer=TfidfTransformer().fit(messages_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "message_tfidf=tfidf_transformer.transform(messages_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading different learning algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=[MultinomialNB(),LogisticRegression(),RandomForestClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Splitting the data set into train test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qn_train,qn_test,label_train,label_test=train_test_split(train['question'],train['label'],test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Creating a pipeline of process for training and prediction\n",
    "\n",
    "1. We have vectorized the BOW using the defined function text_process\n",
    "2. Then generate TFIDF of BOW\n",
    "3. Then impliment a perticular classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_process(classifier):\n",
    "    pipeline=Pipeline([\n",
    "        ('bow',CountVectorizer(analyzer=text_process)),\n",
    "        ('tfidf',TfidfTransformer()),\n",
    "        ('classifier',classifier)\n",
    "    ])\n",
    "    pipeline.fit(qn_train,label_train)\n",
    "    return pipeline.predict(qn_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Checking confusion matrix and derived F1 score for individual classifier\n",
    " And find that Random forest classifier has F1 score above 92 which is comparatively high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "\n",
      "\n",
      "             affirmation  unknown  what  when  who\n",
      "affirmation            1        5    30     0    1\n",
      "unknown                0       43    40     0    6\n",
      "what                   0        0   174     0    2\n",
      "when                   0        1    28     1    1\n",
      "who                    0        0    21     0   89\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "affirmation       1.00      0.03      0.05        37\n",
      "    unknown       0.88      0.48      0.62        89\n",
      "       what       0.59      0.99      0.74       176\n",
      "       when       1.00      0.03      0.06        31\n",
      "        who       0.90      0.81      0.85       110\n",
      "\n",
      "avg / total       0.79      0.70      0.64       443\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "             affirmation  unknown  what  when  who\n",
      "affirmation           26        5     6     0    0\n",
      "unknown                0       66    20     0    3\n",
      "what                   0        0   174     1    1\n",
      "when                   0        1     6    24    0\n",
      "who                    0        0     1     0  109\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "affirmation       1.00      0.70      0.83        37\n",
      "    unknown       0.92      0.74      0.82        89\n",
      "       what       0.84      0.99      0.91       176\n",
      "       when       0.96      0.77      0.86        31\n",
      "        who       0.96      0.99      0.98       110\n",
      "\n",
      "avg / total       0.91      0.90      0.90       443\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "             affirmation  unknown  what  when  who\n",
      "affirmation           33        3     0     0    1\n",
      "unknown                2       76     8     0    3\n",
      "what                   1        0   174     1    0\n",
      "when                   0        1     5    25    0\n",
      "who                    1        4     2     0  103\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "affirmation       0.89      0.89      0.89        37\n",
      "    unknown       0.90      0.85      0.88        89\n",
      "       what       0.92      0.99      0.95       176\n",
      "       when       0.96      0.81      0.88        31\n",
      "        who       0.96      0.94      0.95       110\n",
      "\n",
      "avg / total       0.93      0.93      0.93       443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "\n",
    "for classify in classifier:\n",
    "    predictions=complete_process(classify)\n",
    "    print(classifier[i])\n",
    "    print('\\n')\n",
    "    print(pd.DataFrame(confusion_matrix(label_test,predictions,labels=['affirmation','unknown','what','when','who']),columns=['affirmation','unknown','what','when','who'],index=['affirmation','unknown','what','when','who']))    \n",
    "    print('\\n')\n",
    "    print(classification_report(label_test,predictions))\n",
    "    i=i+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
